{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IjBruu7rDYOz"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models  # <-- Make sure to add this import for models\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Configuration and Settings\n",
        "# =========================\n",
        "\n",
        "class Config:\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Data paths\n",
        "    data_paths = {\n",
        "        '1_12': r'/content/Final Testing Dataset',\n",
        "        '1_4': r'/content/1-4',\n",
        "        '5_8': r'/content/5-8',\n",
        "        '9_12': r'/content/9-12',\n",
        "        'Top': r'/content/Top_level'\n",
        "    }\n",
        "\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'num_workers': 4,\n",
        "        'epochs': 50\n",
        "    }\n",
        "\n",
        "    # Learning rates for different models\n",
        "    learning_rates = {\n",
        "        '1_12': 0.001,\n",
        "        '1_4': 0.0001,\n",
        "        '5_8': 0.0001,\n",
        "        '9_12': 0.0001,\n",
        "        'Top': 0.0001\n",
        "    }\n",
        "\n",
        "    # Number of classes for each model\n",
        "    num_classes = {\n",
        "        '1_12': 12,\n",
        "        '1_4': 4,\n",
        "        '5_8': 4,\n",
        "        '9_12': 4,\n",
        "        'Top': 3\n",
        "    }\n",
        "\n",
        "    # Model save paths\n",
        "    model_save_paths = {\n",
        "        '1_12': '1_12_bats.pth',\n",
        "        '1_4': '1_4_model.pth',\n",
        "        '5_8': '5_8_model.pth',\n",
        "        '9_12': '9_12_model.pth',\n",
        "        'Top': 'top_model.pth'\n",
        "    }\n",
        "\n",
        "# Initialize configuration\n",
        "cfg = Config()\n",
        "\n"
      ],
      "metadata": {
        "id": "fDNmifR-4Y7G"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Data Handling Functions\n",
        "# =========================\n",
        "\n",
        "def get_data_transforms():\n",
        "    \"\"\"Define and return data transformations.\"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomRotation(45)\n",
        "    ])\n",
        "\n",
        "def load_dataset(root_dir, transform):\n",
        "    \"\"\"\n",
        "    Load dataset using ImageFolder.\n",
        "\n",
        "    Args:\n",
        "        root_dir (str): Path to the dataset directory.\n",
        "        transform (torchvision.transforms.Compose): Transformations to apply.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.data.Dataset: Loaded dataset.\n",
        "    \"\"\"\n",
        "    return datasets.ImageFolder(root=root_dir, transform=transform)\n",
        "\n",
        "def split_dataset(dataset, val_ratio=0.2, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Split dataset into training, validation, and test sets.\n",
        "\n",
        "    Args:\n",
        "        dataset (torch.utils.data.Dataset): The dataset to split.\n",
        "        val_ratio (float): Fraction of data for validation.\n",
        "        test_ratio (float): Fraction of data for testing.\n",
        "\n",
        "    Returns:\n",
        "        tuple: train_dataset, val_dataset, test_dataset\n",
        "    \"\"\"\n",
        "    total_size = len(dataset)\n",
        "    val_size = int(val_ratio * total_size)\n",
        "    test_size = int(test_ratio * total_size)\n",
        "    train_size = total_size - val_size - test_size\n",
        "    return random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "def get_dataloaders(train_dataset, val_dataset, test_dataset, batch_size, num_workers):\n",
        "    \"\"\"\n",
        "    Create DataLoaders for training, validation, and testing.\n",
        "\n",
        "    Args:\n",
        "        train_dataset (torch.utils.data.Dataset): Training dataset.\n",
        "        val_dataset (torch.utils.data.Dataset): Validation dataset.\n",
        "        test_dataset (torch.utils.data.Dataset): Test dataset.\n",
        "        batch_size (int): Batch size.\n",
        "        num_workers (int): Number of subprocesses for data loading.\n",
        "\n",
        "    Returns:\n",
        "        tuple: train_loader, val_loader, test_loader\n",
        "    \"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "U4Pcol124h8A"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Training and Evaluation Functions\n",
        "# =========================\n",
        "\n",
        "def train_model(model, train_loader, val_loader, loss_fn, optimizer, device, epochs, model_name):\n",
        "    \"\"\"\n",
        "    Train the given model and validate after each epoch.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        val_loader (DataLoader): DataLoader for validation data.\n",
        "        loss_fn (nn.Module): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        device (torch.device): Device to train on.\n",
        "        epochs (int): Number of epochs.\n",
        "        model_name (str): Name identifier for the model.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: Trained model.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        print(f\"Epoch: {epoch + 1}/{epochs} - Model: {model_name}\")\n",
        "        pbar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in pbar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix({'Loss': f\"{running_loss / (total):.4f}\",\n",
        "                              'Accuracy': f\"{correct / total:.4f}\"})\n",
        "\n",
        "        # Validation after each epoch\n",
        "        val_acc, val_loss = evaluate_model(model, val_loader, loss_fn, device)\n",
        "        print(f\"Validation - Accuracy: {val_acc:.4f}, Loss: {val_loss:.4f}\\n\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, data_loader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to evaluate.\n",
        "        data_loader (DataLoader): DataLoader for the dataset.\n",
        "        loss_fn (nn.Module): Loss function.\n",
        "        device (torch.device): Device to evaluate on.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Accuracy, Average Loss\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    return accuracy, avg_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "O5Vv-s_R4mHo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Combined Model Class\n",
        "# =========================\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined model that uses a top-level model to decide which specialized model to use for each input.\n",
        "    \"\"\"\n",
        "    def __init__(self, top_model, specialized_models, device):\n",
        "        \"\"\"\n",
        "        Initialize the CombinedModel.\n",
        "\n",
        "        Args:\n",
        "            top_model (nn.Module): The top-level model.\n",
        "            specialized_models (dict): Dictionary of specialized models.\n",
        "            device (torch.device): Device to run the models on.\n",
        "        \"\"\"\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.top_model = top_model\n",
        "        self.specialized_models = nn.ModuleDict(specialized_models)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the combined model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Combined output tensor.\n",
        "        \"\"\"\n",
        "        # Get decisions from the top-level model\n",
        "        decision_logits = self.top_model(x)\n",
        "        decisions = torch.argmax(decision_logits, dim=1)  # Shape: (batch_size,)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        total_classes = sum([cfg.num_classes[key] for key in self.specialized_models.keys()])\n",
        "        combined_outputs = torch.zeros(batch_size, total_classes).to(self.device)\n",
        "\n",
        "        # Process inputs in batches based on decisions\n",
        "        for decision, model_key in enumerate(self.specialized_models.keys()):\n",
        "            indices = (decisions == decision).nonzero(as_tuple=True)[0]\n",
        "            if len(indices) == 0:\n",
        "                continue  # No samples for this decision\n",
        "            subset = x[indices]\n",
        "            outputs = self.specialized_models[model_key](subset)\n",
        "            # Determine the class index offset\n",
        "            class_offset = sum([cfg.num_classes[key] for key in list(self.specialized_models.keys())[:decision]])\n",
        "            combined_outputs[indices, class_offset:class_offset + cfg.num_classes[model_key]] = outputs\n",
        "\n",
        "        return combined_outputs\n"
      ],
      "metadata": {
        "id": "EU3AeRuL4pax"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Train and Save Model Function\n",
        "# =========================\n",
        "\n",
        "\n",
        "def train_and_save_model(model_key, model, train_loader, val_loader):\n",
        "    \"\"\"\n",
        "    Train and save a model given its key, train_loader, and val_loader.\n",
        "\n",
        "    Args:\n",
        "        model_key (str): The identifier for the model (e.g., '1_4', '5_8', '9_12').\n",
        "        model (nn.Module): The model to train.\n",
        "        train_loader (DataLoader): DataLoader for training.\n",
        "        val_loader (DataLoader): DataLoader for validation.\n",
        "    \"\"\"\n",
        "    print(f\"Training model {model_key}...\")\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rates[model_key])\n",
        "\n",
        "    # Check if model file exists\n",
        "    model_path = cfg.model_save_paths[model_key]\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Loading existing {model_key} model...\")\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    else:\n",
        "        print(f\"Training new {model_key} model...\")\n",
        "        # Train the model\n",
        "        model = train_model(model, train_loader, val_loader, loss_fn, optimizer, cfg.device, epochs=cfg.training_params['epochs'], model_name=model_key)\n",
        "\n",
        "        # Save the model after training\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"{model_key} model saved successfully!\")"
      ],
      "metadata": {
        "id": "1nFSJUmwGRsw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Early Stopper Class\n",
        "# =========================\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How many epochs to wait after last time validation loss improved.\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n"
      ],
      "metadata": {
        "id": "R-DppvXiF9QM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Main Execution Flow\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    # Define transformations for image processing\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images\n",
        "        transforms.ToTensor(),  # Convert to tensor\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "    ])\n",
        "\n",
        "    # Check and print the directory structure and file counts\n",
        "    print(\"Verifying dataset structure and files:\")\n",
        "    for root, dirs, files in os.walk(cfg.data_paths['1_12']):\n",
        "        print(root, len(files))  # Shows number of files in each directory\n",
        "\n",
        "    # Load the test dataset for combined evaluation\n",
        "    test_root_dir = cfg.data_paths['1_12']\n",
        "    test_dataset = load_dataset(test_root_dir, transform)\n",
        "    _, _, combined_test_loader = get_dataloaders(\n",
        "        *split_dataset(test_dataset),\n",
        "        cfg.training_params['batch_size'],\n",
        "        cfg.training_params['num_workers']\n",
        "    )\n",
        "\n",
        "    # Define the top-level model (you can choose any architecture or custom model)\n",
        "    top_model = models.resnet18(pretrained=False)  # Example: ResNet-18\n",
        "    top_model.fc = nn.Linear(top_model.fc.in_features, cfg.num_classes['Top'])  # Adjust the output for 3 classes\n",
        "\n",
        "    # Define specialized models (one for each subset of classes)\n",
        "    specialized_models = {\n",
        "        '1_4': models.resnet18(pretrained=False),\n",
        "        '5_8': models.resnet18(pretrained=False),\n",
        "        '9_12': models.resnet18(pretrained=False)\n",
        "    }\n",
        "\n",
        "    # Adjust the output layers of each specialized model\n",
        "    specialized_models['1_4'].fc = nn.Linear(specialized_models['1_4'].fc.in_features, cfg.num_classes['1_4'])\n",
        "    specialized_models['5_8'].fc = nn.Linear(specialized_models['5_8'].fc.in_features, cfg.num_classes['5_8'])\n",
        "    specialized_models['9_12'].fc = nn.Linear(specialized_models['9_12'].fc.in_features, cfg.num_classes['9_12'])\n",
        "\n",
        "    # Define the CombinedModel\n",
        "    combined_model = CombinedModel(top_model, specialized_models, cfg.device)\n",
        "    combined_model.to(cfg.device)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    loss_fn = nn.CrossEntropyLoss()  # For classification tasks\n",
        "    optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "\n",
        "    # Check if model file exists\n",
        "    model_path = \"combined_model.pth\"\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"Loading existing model...\")\n",
        "        combined_model.load_state_dict(torch.load(model_path))\n",
        "    else:\n",
        "        print(\"Training new model...\")\n",
        "        # Train the model if not already saved\n",
        "        combined_model = train_model(combined_model, combined_test_loader, combined_test_loader, loss_fn, optimizer, cfg.device, epochs=10, model_name='combined_model')\n",
        "\n",
        "        # Save the model after training\n",
        "        torch.save(combined_model.state_dict(), model_path)\n",
        "        print(\"Model saved successfully!\")\n",
        "\n",
        "    # Evaluate the combined model\n",
        "    evaluate_model(combined_model, combined_test_loader, loss_fn, cfg.device)\n",
        "\n",
        "    # Save the evaluated model\n",
        "    torch.save(combined_model.state_dict(), \"combined_model_evaluated.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "x0Jg_5bt4saS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cada4682-de01-447f-9be3-c1d2338198d4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying dataset structure and files:\n",
            "/content/Final Testing Dataset 0\n",
            "/content/Final Testing Dataset/12 500\n",
            "/content/Final Testing Dataset/9 500\n",
            "/content/Final Testing Dataset/1 501\n",
            "/content/Final Testing Dataset/8 500\n",
            "/content/Final Testing Dataset/5 500\n",
            "/content/Final Testing Dataset/4 500\n",
            "/content/Final Testing Dataset/3 500\n",
            "/content/Final Testing Dataset/2 500\n",
            "/content/Final Testing Dataset/10 500\n",
            "/content/Final Testing Dataset/11 500\n",
            "/content/Final Testing Dataset/6 500\n",
            "/content/Final Testing Dataset/7 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-de8fffe06f6f>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  combined_model.load_state_dict(torch.load(model_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Main Execution Flow (New)\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    # Define transformations for image processing\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images\n",
        "        transforms.ToTensor(),  # Convert to tensor\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "    ])\n",
        "\n",
        "    # Models and their corresponding datasets\n",
        "    model_info = {\n",
        "        '1_4': cfg.data_paths['1_4'],\n",
        "        '5_8': cfg.data_paths['5_8'],\n",
        "        '9_12': cfg.data_paths['9_12'],\n",
        "        '1_12': cfg.data_paths['1_12']\n",
        "    }\n",
        "\n",
        "    # Train each model separately\n",
        "    for model_key, dataset_path in model_info.items():\n",
        "        print(f\"\\nTraining model {model_key}...\")\n",
        "\n",
        "        # Load the dataset for this model\n",
        "        dataset = load_dataset(dataset_path, transform)\n",
        "        train_loader, val_loader, test_loader = get_dataloaders(\n",
        "            *split_dataset(dataset),\n",
        "            cfg.training_params['batch_size'],\n",
        "            cfg.training_params['num_workers']\n",
        "        )\n",
        "\n",
        "        # Define the model with appropriate number of classes\n",
        "        model = models.resnet18(pretrained=False)\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),  # Add dropout to reduce overfitting\n",
        "            nn.Linear(model.fc.in_features, cfg.num_classes[model_key])  # Adjust output layer\n",
        "        )\n",
        "\n",
        "        # Define loss function, optimizer, and scheduler\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rates[model_key])\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "        early_stopper = EarlyStopping(patience=5, delta=0.01)\n",
        "\n",
        "        # Train the model\n",
        "        for epoch in range(cfg.training_params['epochs']):\n",
        "            print(f\"Epoch: {epoch + 1}/{cfg.training_params['epochs']} - Model: {model_key}\")\n",
        "\n",
        "            # Train for one epoch\n",
        "            model = train_model(model, train_loader, val_loader, loss_fn, optimizer, cfg.device, epochs=1, model_name=model_key)\n",
        "\n",
        "            # Validation after each epoch\n",
        "            val_acc, val_loss = evaluate_model(model, val_loader, loss_fn, cfg.device)\n",
        "            print(f\"Validation - Accuracy: {val_acc:.4f}, Loss: {val_loss:.4f}\")\n",
        "\n",
        "            # Adjust learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            # Early stopping check\n",
        "            early_stopper(val_loss)\n",
        "            if early_stopper.early_stop:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Save the trained model\n",
        "        torch.save(model.state_dict(), cfg.model_save_paths[model_key])\n",
        "        print(f\"{model_key} model saved successfully!\")\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        print(f\"Evaluating {model_key} model on test data...\")\n",
        "        test_acc, test_loss = evaluate_model(model, test_loader, loss_fn, cfg.device)\n",
        "        print(f\"Test - Accuracy: {test_acc:.4f}, Loss: {test_loss:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq10n4tkGIwO",
        "outputId": "63992467-a1c1-4196-f3d9-1bb46c9348ab"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model 1_4...\n",
            "Epoch: 1/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.67it/s, Loss=0.0242, Accuracy=0.6661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3050, Loss: 1.8130\n",
            "\n",
            "Validation - Accuracy: 0.3050, Loss: 1.8130\n",
            "Epoch: 2/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.17it/s, Loss=0.0135, Accuracy=0.8218]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.6450, Loss: 1.0591\n",
            "\n",
            "Validation - Accuracy: 0.6450, Loss: 1.0591\n",
            "Epoch: 3/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  7.50it/s, Loss=0.0105, Accuracy=0.8751]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7775, Loss: 0.5376\n",
            "\n",
            "Validation - Accuracy: 0.7775, Loss: 0.5376\n",
            "Epoch: 4/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.10it/s, Loss=0.0080, Accuracy=0.9084]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.6100, Loss: 1.1798\n",
            "\n",
            "Validation - Accuracy: 0.6100, Loss: 1.1798\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 5/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  6.74it/s, Loss=0.0070, Accuracy=0.9167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7525, Loss: 0.6104\n",
            "\n",
            "Validation - Accuracy: 0.7525, Loss: 0.6104\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 6/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.08it/s, Loss=0.0048, Accuracy=0.9475]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8050, Loss: 0.5622\n",
            "\n",
            "Validation - Accuracy: 0.8050, Loss: 0.5622\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch: 7/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  7.05it/s, Loss=0.0032, Accuracy=0.9667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7050, Loss: 0.7755\n",
            "\n",
            "Validation - Accuracy: 0.7050, Loss: 0.7755\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch: 8/50 - Model: 1_4\n",
            "Epoch: 1/1 - Model: 1_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.15it/s, Loss=0.0024, Accuracy=0.9817]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.5725, Loss: 2.4156\n",
            "\n",
            "Validation - Accuracy: 0.5725, Loss: 2.4156\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping triggered.\n",
            "1_4 model saved successfully!\n",
            "Evaluating 1_4 model on test data...\n",
            "Test - Accuracy: 0.5925, Loss: 2.3114\n",
            "\n",
            "Training model 5_8...\n",
            "Epoch: 1/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.14it/s, Loss=0.0307, Accuracy=0.5733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.5425, Loss: 0.9905\n",
            "\n",
            "Validation - Accuracy: 0.5425, Loss: 0.9905\n",
            "Epoch: 2/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.63it/s, Loss=0.0135, Accuracy=0.8283]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7675, Loss: 0.5654\n",
            "\n",
            "Validation - Accuracy: 0.7675, Loss: 0.5654\n",
            "Epoch: 3/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.21it/s, Loss=0.0094, Accuracy=0.8875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7750, Loss: 0.5515\n",
            "\n",
            "Validation - Accuracy: 0.7750, Loss: 0.5515\n",
            "Epoch: 4/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  7.24it/s, Loss=0.0063, Accuracy=0.9308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7275, Loss: 0.9406\n",
            "\n",
            "Validation - Accuracy: 0.7275, Loss: 0.9406\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 5/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.11it/s, Loss=0.0033, Accuracy=0.9767]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7875, Loss: 0.7085\n",
            "\n",
            "Validation - Accuracy: 0.7875, Loss: 0.7085\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 6/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  6.97it/s, Loss=0.0026, Accuracy=0.9783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8400, Loss: 0.4589\n",
            "\n",
            "Validation - Accuracy: 0.8400, Loss: 0.4589\n",
            "Epoch: 7/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.08it/s, Loss=0.0025, Accuracy=0.9775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.4800, Loss: 4.8649\n",
            "\n",
            "Validation - Accuracy: 0.4800, Loss: 4.8649\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 8/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.99it/s, Loss=0.0025, Accuracy=0.9783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8275, Loss: 0.5594\n",
            "\n",
            "Validation - Accuracy: 0.8275, Loss: 0.5594\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 9/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.72it/s, Loss=0.0009, Accuracy=0.9983]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8650, Loss: 0.4167\n",
            "\n",
            "Validation - Accuracy: 0.8650, Loss: 0.4167\n",
            "Epoch: 10/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.02it/s, Loss=0.0005, Accuracy=0.9975]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7925, Loss: 0.9134\n",
            "\n",
            "Validation - Accuracy: 0.7925, Loss: 0.9134\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 11/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  7.42it/s, Loss=0.0005, Accuracy=0.9983]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8475, Loss: 0.4386\n",
            "\n",
            "Validation - Accuracy: 0.8475, Loss: 0.4386\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 12/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.06it/s, Loss=0.0004, Accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8625, Loss: 0.4214\n",
            "\n",
            "Validation - Accuracy: 0.8625, Loss: 0.4214\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch: 13/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  7.05it/s, Loss=0.0003, Accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8600, Loss: 0.4221\n",
            "\n",
            "Validation - Accuracy: 0.8600, Loss: 0.4221\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch: 14/50 - Model: 5_8\n",
            "Epoch: 1/1 - Model: 5_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.17it/s, Loss=0.0003, Accuracy=0.9992]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8575, Loss: 0.4194\n",
            "\n",
            "Validation - Accuracy: 0.8575, Loss: 0.4194\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping triggered.\n",
            "5_8 model saved successfully!\n",
            "Evaluating 5_8 model on test data...\n",
            "Test - Accuracy: 0.8850, Loss: 0.2967\n",
            "\n",
            "Training model 9_12...\n",
            "Epoch: 1/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.99it/s, Loss=0.0397, Accuracy=0.3933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.2600, Loss: 3.4355\n",
            "\n",
            "Validation - Accuracy: 0.2600, Loss: 3.4355\n",
            "Epoch: 2/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.75it/s, Loss=0.0289, Accuracy=0.5558]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.4850, Loss: 0.9658\n",
            "\n",
            "Validation - Accuracy: 0.4850, Loss: 0.9658\n",
            "Epoch: 3/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.89it/s, Loss=0.0223, Accuracy=0.6783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.6125, Loss: 0.8934\n",
            "\n",
            "Validation - Accuracy: 0.6125, Loss: 0.8934\n",
            "Epoch: 4/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  7.87it/s, Loss=0.0136, Accuracy=0.8517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.5150, Loss: 1.1209\n",
            "\n",
            "Validation - Accuracy: 0.5150, Loss: 1.1209\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 5/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.07it/s, Loss=0.0071, Accuracy=0.9450]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.4500, Loss: 2.6284\n",
            "\n",
            "Validation - Accuracy: 0.4500, Loss: 2.6284\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 6/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  7.53it/s, Loss=0.0041, Accuracy=0.9750]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.4500, Loss: 2.1593\n",
            "\n",
            "Validation - Accuracy: 0.4500, Loss: 2.1593\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch: 7/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:04<00:00,  8.10it/s, Loss=0.0026, Accuracy=0.9867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.5050, Loss: 1.7863\n",
            "\n",
            "Validation - Accuracy: 0.5050, Loss: 1.7863\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch: 8/50 - Model: 9_12\n",
            "Epoch: 1/1 - Model: 9_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 38/38 [00:05<00:00,  7.24it/s, Loss=0.0022, Accuracy=0.9858]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3025, Loss: 3.0834\n",
            "\n",
            "Validation - Accuracy: 0.3025, Loss: 3.0834\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping triggered.\n",
            "9_12 model saved successfully!\n",
            "Evaluating 9_12 model on test data...\n",
            "Test - Accuracy: 0.2675, Loss: 2.9261\n",
            "\n",
            "Training model 1_12...\n",
            "Epoch: 1/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.28it/s, Loss=0.0408, Accuracy=0.4893]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3317, Loss: 2.0918\n",
            "\n",
            "Validation - Accuracy: 0.3317, Loss: 2.0918\n",
            "Epoch: 2/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.19it/s, Loss=0.0278, Accuracy=0.6312]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7275, Loss: 0.6922\n",
            "\n",
            "Validation - Accuracy: 0.7275, Loss: 0.6922\n",
            "Epoch: 3/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.26it/s, Loss=0.0243, Accuracy=0.6623]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7000, Loss: 0.6942\n",
            "\n",
            "Validation - Accuracy: 0.7000, Loss: 0.6942\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 4/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.31it/s, Loss=0.0219, Accuracy=0.6945]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.5233, Loss: 1.3414\n",
            "\n",
            "Validation - Accuracy: 0.5233, Loss: 1.3414\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 5/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.33it/s, Loss=0.0199, Accuracy=0.7245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7458, Loss: 0.6068\n",
            "\n",
            "Validation - Accuracy: 0.7458, Loss: 0.6068\n",
            "Epoch: 6/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.30it/s, Loss=0.0190, Accuracy=0.7370]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.6550, Loss: 0.8418\n",
            "\n",
            "Validation - Accuracy: 0.6550, Loss: 0.8418\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 7/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.25it/s, Loss=0.0183, Accuracy=0.7545]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7550, Loss: 0.5498\n",
            "\n",
            "Validation - Accuracy: 0.7550, Loss: 0.5498\n",
            "Epoch: 8/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:14<00:00,  7.98it/s, Loss=0.0167, Accuracy=0.7740]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.7800, Loss: 0.5099\n",
            "\n",
            "Validation - Accuracy: 0.7800, Loss: 0.5099\n",
            "Epoch: 9/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.24it/s, Loss=0.0153, Accuracy=0.7864]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.6692, Loss: 0.7563\n",
            "\n",
            "Validation - Accuracy: 0.6692, Loss: 0.7563\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 10/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.32it/s, Loss=0.0157, Accuracy=0.7884]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.6883, Loss: 0.7161\n",
            "\n",
            "Validation - Accuracy: 0.6883, Loss: 0.7161\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 11/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.30it/s, Loss=0.0118, Accuracy=0.8562]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8242, Loss: 0.4019\n",
            "\n",
            "Validation - Accuracy: 0.8242, Loss: 0.4019\n",
            "Epoch: 12/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.37it/s, Loss=0.0103, Accuracy=0.8736]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8250, Loss: 0.3881\n",
            "\n",
            "Validation - Accuracy: 0.8250, Loss: 0.3881\n",
            "Epoch: 13/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.31it/s, Loss=0.0095, Accuracy=0.8856]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8292, Loss: 0.3893\n",
            "\n",
            "Validation - Accuracy: 0.8292, Loss: 0.3893\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch: 14/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.25it/s, Loss=0.0090, Accuracy=0.8911]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8308, Loss: 0.3791\n",
            "\n",
            "Validation - Accuracy: 0.8308, Loss: 0.3791\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch: 15/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.30it/s, Loss=0.0081, Accuracy=0.9042]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8275, Loss: 0.3865\n",
            "\n",
            "Validation - Accuracy: 0.8275, Loss: 0.3865\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch: 16/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:13<00:00,  8.23it/s, Loss=0.0081, Accuracy=0.9145]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8217, Loss: 0.3991\n",
            "\n",
            "Validation - Accuracy: 0.8217, Loss: 0.3991\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch: 17/50 - Model: 1_12\n",
            "Epoch: 1/1 - Model: 1_12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 113/113 [00:14<00:00,  7.98it/s, Loss=0.0072, Accuracy=0.9175]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.8183, Loss: 0.4133\n",
            "\n",
            "Validation - Accuracy: 0.8183, Loss: 0.4133\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping triggered.\n",
            "1_12 model saved successfully!\n",
            "Evaluating 1_12 model on test data...\n",
            "Test - Accuracy: 0.8183, Loss: 0.4701\n"
          ]
        }
      ]
    }
  ]
}